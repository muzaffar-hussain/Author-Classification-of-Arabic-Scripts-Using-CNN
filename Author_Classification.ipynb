{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writer Verification Project\n",
    "\n",
    "## Description:\n",
    "This project is divided in two parts:\n",
    "1. Data Pre-processing \n",
    "2. Training Model on convNET model(AlexNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import all the necessary libraries for this project. For any python program we can get different libraries that make our tasks easier. You can get more details on each of these libraries in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==4.1.0.25 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (4.1.0.25)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from opencv-python==4.1.0.25) (1.18.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (0.5.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==0.23.4 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from pandas==0.23.4) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from pandas==0.23.4) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from pandas==0.23.4) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from python-dateutil>=2.5.0->pandas==0.23.4) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.14.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (0.9.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (0.33.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (3.11.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\muzaf\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (0.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\muzaf\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.14.0) (0.1.7)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (1.26.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorflow==1.14.0) (1.18.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (45.1.0.post20200127)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from keras==2.2.4) (1.18.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from keras==2.2.4) (1.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from keras==2.2.4) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from keras==2.2.4) (5.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: split_folders in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (0.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib==3.0.2 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from matplotlib==3.0.2) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from matplotlib==3.0.2) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from matplotlib==3.0.2) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.10.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from matplotlib==3.0.2) (1.18.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from matplotlib==3.0.2) (0.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib==3.0.2) (45.1.0.post20200127)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (from python-dateutil>=2.1->matplotlib==3.0.2) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow==5.4.0 in c:\\users\\muzaf\\anaconda3\\envs\\emmy\\lib\\site-packages (5.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python==4.1.0.25\n",
    "# !pip install imutils\n",
    "# !pip install pandas==0.23.4\n",
    "# !pip install tensorflow==1.14.0\n",
    "# !pip install keras==2.2.4\n",
    "# !pip install split_folders\n",
    "# !pip install matplotlib==3.0.2\n",
    "# !pip install Pillow==5.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import csv\n",
    "import math\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import imutils\n",
    "import numpy as np\n",
    "import split_folders\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import MaxPooling2D, Conv2D, Reshape, Dense, Input, Flatten, GlobalAveragePooling2D,Convolution2D, Activation, Dropout\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation:\n",
    "\n",
    "For this part we need to acquire pathches from the images of each author so that we can train our algorithm to recognize the work/writing pattern of the author.\n",
    "\n",
    "For this we will use image opencv to detect contours in the image & copy them to a new file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the next cell I have done some image processing tasks so that only the writings are visible for making patches.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = cv2.imread(\"raw_data/1/DSC00005.jpg\")\n",
    "image = cv2.resize(pic,(int(pic.shape[1]/2),int(pic.shape[0]/2))) \n",
    "cv2.imshow(\"Orignal Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# Converting image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Converting it to binary mapping\n",
    "ret,thresh1 = cv2.threshold(gray,50,255,cv2.THRESH_BINARY_INV)\n",
    "# Applying morphology\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "closing = cv2.morphologyEx(thresh1, cv2.MORPH_CLOSE, kernel)\n",
    "# Resulting Image\n",
    "cv2.imshow(\"Final Image\", thresh1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we get that value we will extract the area only with some writing in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(closing, 1, 3)\n",
    "idx = 0\n",
    "x,y,w,h = (2000,2000,0,0)\n",
    "for cnt in contours:\n",
    "    idx += 1\n",
    "    x_x, y_y, w_w, h_h = cv2.boundingRect(cnt)\n",
    "    if x_x<x:\n",
    "        x=x_x\n",
    "    if y_y<y:\n",
    "        y=y_y\n",
    "    if x_x>w:\n",
    "        w=x_x\n",
    "    if y_y>h:\n",
    "        h=y_y\n",
    "crop_img = image[y:h, x:w]\n",
    "crop_img_inv = thresh1[y:h, x:w]\n",
    "cv2.imshow(\"Final Image\", crop_img_inv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to extract patches of same dimensions so we this code will do.\n",
    "\n",
    "**NOTE**\n",
    "1. We will also add a check if the intensity is less than so don't include that patch as it will not have much values in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\numpy\\lib\\function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "(dimx,dimy,c) = crop_img.shape\n",
    "div = 10\n",
    "if crop_img.shape[0]>crop_img.shape[1]:\n",
    "    patch_shape = (int(dimx/div),int(dimx/div))\n",
    "    stride = (div*crop_img.shape[1]/int(dimx/div))\n",
    "else:\n",
    "    patch_shape = (int(dimy/div),int(dimy/div))\n",
    "    stride = (div*crop_img.shape[0]/int(dimy/div))\n",
    "s_path = \"results\"\n",
    "if not os.path.exists(s_path):\n",
    "    os.makedirs(s_path)\n",
    "def patchify(img, patch_shape):\n",
    "    img = np.ascontiguousarray(img)  # won't make a copy if not needed\n",
    "    X, Y, C = img.shape\n",
    "    h, w = patch_shape\n",
    "    x,y = 0,0\n",
    "    for i in range(0,200):\n",
    "        crop = crop_img[y:y+h, x:x+w]\n",
    "        crop_inv = crop_img_inv[y:y+h, x:x+w]\n",
    "        x += h\n",
    "        Intensity = np.average(crop_inv)\n",
    "        if Intensity<6:\n",
    "            continue\n",
    "        if (crop.shape!=(h,w,C)):\n",
    "            x = 0\n",
    "            y += h\n",
    "            continue\n",
    "        try:\n",
    "            crop = cv2.resize(crop,(224,224))\n",
    "            cv2.imwrite(s_path + \"/{}.jpg\".format(i),crop)\n",
    "        except:\n",
    "            x = 0\n",
    "            y += h\n",
    "            continue\n",
    "    \n",
    "    return\n",
    "patches = patchify(crop_img,patch_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add all these functionalities to function that will do all that task. But first let us see how can we access all these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify(crop_img, crop_img_inv, patch_shape,subdir,file):\n",
    "    save_in = s_path+\"/\"+subdir\n",
    "    if not os.path.exists(save_in):\n",
    "        os.makedirs(save_in)\n",
    "    img = np.ascontiguousarray(crop_img)  # won't make a copy if not needed\n",
    "    X, Y, C = img.shape\n",
    "    h, w = patch_shape\n",
    "    x,y = 0,0\n",
    "    for i in range(0,200):\n",
    "        crop = crop_img[y:y+h, x:x+w]\n",
    "        crop_inv = crop_img_inv[y:y+h, x:x+w]\n",
    "        x += h\n",
    "        Intensity = np.average(crop_inv)\n",
    "        if Intensity<6:\n",
    "            continue\n",
    "        if (crop.shape!=(h,w,C)):\n",
    "            x = 0\n",
    "            y += h\n",
    "            continue\n",
    "        try:\n",
    "            crop = cv2.resize(crop,(224,224))\n",
    "            cv2.imwrite(save_in + \"/{}_{}_{}.jpg\".format(subdir,file,i),crop)\n",
    "        except:\n",
    "            x = 0\n",
    "            y += h\n",
    "            continue\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patches_extraction(path,s_path):\n",
    "    for subdir in os.listdir(path):\n",
    "        print(\"The directory name is: \",subdir)\n",
    "        name = 0\n",
    "        for file in os.listdir(path+\"/\"+ subdir):\n",
    "            print(\"The file name is: \",file)\n",
    "            name += 1\n",
    "            if not file.endswith(\".jpg\"):\n",
    "                continue\n",
    "            pic = cv2.imread(path+\"/\"+ subdir+\"/\"+file)\n",
    "            image = cv2.resize(pic,(int(pic.shape[1]/2),int(pic.shape[0]/2))) \n",
    "            # cv2.imshow(\"Orignal Image\", image)\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyAllWindows()\n",
    "            # Converting image to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # Converting it to binary mapping\n",
    "            ret,thresh1 = cv2.threshold(gray,50,255,cv2.THRESH_BINARY_INV)\n",
    "            # Applying morphology\n",
    "            kernel = np.ones((5,5),np.uint8)\n",
    "            closing = cv2.morphologyEx(thresh1, cv2.MORPH_CLOSE, kernel)\n",
    "            contours, hierarchy = cv2.findContours(closing, 1, 3)\n",
    "            idx = 0\n",
    "            x,y,w,h = (2000,2000,0,0)\n",
    "            for cnt in contours:\n",
    "                idx += 1\n",
    "                x_x, y_y, w_w, h_h = cv2.boundingRect(cnt)\n",
    "                if x_x<x:\n",
    "                    x=x_x\n",
    "                if y_y<y:\n",
    "                    y=y_y\n",
    "                if x_x>w:\n",
    "                    w=x_x\n",
    "                if y_y>h:\n",
    "                    h=y_y\n",
    "            crop_img = image[y:h, x:w]\n",
    "            crop_img_inv = thresh1[y:h, x:w]\n",
    "            (dimx,dimy,c) = crop_img.shape\n",
    "            div = 10\n",
    "            if crop_img.shape[0]>crop_img.shape[1]:\n",
    "                patch_shape = (int(dimx/div),int(dimx/div))\n",
    "            else:\n",
    "                patch_shape = (int(dimy/div),int(dimy/div))\n",
    "            patches = patchify(crop_img, crop_img_inv,patch_shape,subdir,name)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will gonna run this on the whole data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory name is:  1\n",
      "The file name is:  DSC00005.jpg\n",
      "The file name is:  DSC00175.jpg\n",
      "The directory name is:  2\n",
      "The file name is:  DSC00004.jpg\n",
      "The file name is:  DSC00005.jpg\n",
      "The file name is:  DSC00025.jpg\n",
      "The directory name is:  3\n",
      "The file name is:  DSC00004.jpg\n",
      "The file name is:  DSC00006.jpg\n",
      "The file name is:  DSC00353.jpg\n",
      "The directory name is:  4\n",
      "The file name is:  DSC00003.jpg\n",
      "The file name is:  DSC00005.jpg\n",
      "The directory name is:  5\n",
      "The file name is:  DSC00004.jpg\n",
      "The file name is:  DSC00163.jpg\n",
      "The directory name is:  6\n",
      "The file name is:  DSC00005.jpg\n",
      "The file name is:  DSC00156.jpg\n",
      "The directory name is:  7\n",
      "The file name is:  DSC00005.jpg\n",
      "The file name is:  DSC00006.jpg\n",
      "The file name is:  DSC00062.jpg\n",
      "The directory name is:  8\n",
      "The file name is:  DSC00005.jpg\n",
      "The file name is:  DSC00634.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = (\"C:/Users/muzaf/Documents/GitHub/Text_detection/raw_data\")\n",
    "s_path = (\"C:/Users/muzaf/Documents/GitHub/Text_detection/processed_data\")\n",
    "patches_extraction(path,s_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split our data into train & test dataset. We will use the library \"https://pypi.org/project/split-folders/\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1473 files [00:08, 174.11 files/s]\n"
     ]
    }
   ],
   "source": [
    "s_path = (\"C:/Users/muzaf/Documents/GitHub/Text_detection/processed_data\")\n",
    "split_path = (\"C:/Users/muzaf/Documents/GitHub/Text_detection/split_data\")\n",
    "if not os.path.exists(split_path):\n",
    "        os.makedirs(split_path)\n",
    "split_folders.ratio(s_path, output=split_path, seed=1337, ratio=(.8, .1, .1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is all set for training! :) We will now make the model.\n",
    "In this cell we initialize some parameters that will be given to our model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data_path = r'C:\\Users\\muzaf\\Documents\\GitHub\\Text_detection\\split_data\\train'\n",
    "validation_data_path = r'C:\\Users\\muzaf\\Documents\\GitHub\\Text_detection\\split_data\\val'\n",
    "test_data_path = r'C:\\Users\\muzaf\\Documents\\GitHub\\Text_detection\\split_data\\test'\n",
    "\n",
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "epochs = 10\n",
    "lr = 0.0004\n",
    "\n",
    "'''\n",
    "Call Backs\n",
    "'''\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\",\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet Model\n",
    "\n",
    "Now as discussed in paper they used an AlexNet model for training so here is the model. You can compare the model summary with that in the paper & it is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 8008      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 28,045,488\n",
      "Trainable params: 28,045,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\muzaf\\Anaconda3\\envs\\emmy\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "#Instantiate an empty model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Passing it to a Fully Connected layer\n",
    "model.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 3rd Fully Connected Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will initialize our generators. Generators help us get data as in from all the different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1411 images belonging to 8 classes.\n",
      "Found 323 images belonging to 8 classes.\n",
      "Found 356 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./1,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=6,\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=6,\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to find the step size we use our generators & batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now we will start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "235/235 [==============================] - 142s 605ms/step - loss: 13.5920 - acc: 0.1567 - val_loss: 13.7283 - val_acc: 0.1483\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 13.72835, saving model to weights.01-13.73.hdf5\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 144s 612ms/step - loss: 13.5460 - acc: 0.1596 - val_loss: 13.6775 - val_acc: 0.1514\n",
      "\n",
      "Epoch 00002: val_loss improved from 13.72835 to 13.67750, saving model to weights.02-13.68.hdf5\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 143s 608ms/step - loss: 13.5917 - acc: 0.1567 - val_loss: 13.4233 - val_acc: 0.1672\n",
      "\n",
      "Epoch 00003: val_loss improved from 13.67750 to 13.42327, saving model to weights.03-13.42.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df6ecbce48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=3,\n",
    "                    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "Since we are evaluating the model, we should treat the validation set as if it was the test set. So we should sample the images in the validation set exactly once(if you are planning to evaluate, you need to change the batch size of the valid generator to 1 or something that exactly divides the total num of samples in validation set), but the order doesn’t matter so let “shuffle” be True as it was earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.965660381016296, 0.19558360115022688]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator=validation_generator,\n",
    "steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting from the model\n",
    "\n",
    "You need to reset the test_generator before whenever you call the predict_generator. This is important, if you forget to reset the test_generator you will get outputs in a weird order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 6s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now predicted_class_indices has the predicted labels, but you can’t simply tell what the predictions are, because all you can see is numbers like 0,1,4,1,0,6…\n",
    "You need to map the predicted labels with their unique ids such as filenames to find out what you predicted for which image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '1', 1: '2', 2: '3', 3: '4', 4: '5', 5: '6', 6: '7', 7: '8'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we save the results as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
